{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_file = './dictionary.json'\n",
    "parse_file = './Lexical/Test06.txt'\n",
    "output_file = './result.pasc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = json.load(open(dict_file))\n",
    "raw_text = open(parse_file).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'x = y + 56'\n"
     ]
    }
   ],
   "source": [
    "raw_text = raw_text.replace('\\n', ' \\n')\n",
    "print(repr(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "isComment = 0\n",
    "errors = []\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenParser(token, startRow, startCol, endRow, endCol):\n",
    "    if isComment == 1:\n",
    "        return\n",
    "\n",
    "    if token == '':\n",
    "        return\n",
    "    \n",
    "    if token in dic:\n",
    "        results.append([token, dic[token] + 'number', startRow, endRow, startCol + 1, endCol + 1])\n",
    "        return\n",
    "    else:        \n",
    "        if re.match(r'^[0-9]+$', token):\n",
    "            results.append([token, 'ICONSTnumber', startRow, endRow, startCol + 1, endCol + 1])\n",
    "            return\n",
    "        \n",
    "        if re.match(r'^\\'.\\'$', token):\n",
    "            results.append([token, 'CCONSTnumber', startRow, endRow, startCol + 1, endCol + 1])\n",
    "            return\n",
    "        \n",
    "        if re.match('^\\'.*\\'$', token):\n",
    "            results.append([token, 'SCONSTnumber', startRow, endRow, startCol + 1, endCol + 1])\n",
    "            return\n",
    "                \n",
    "        if re.match(r'^[0-9]+[a-zA-Z0-9]*$', token):\n",
    "            errors.append([startRow, endRow, startCol + 1, endCol + 1, token, '[SYNTAX ERROR]: Can not use this this as an identifier'])\n",
    "            return\n",
    "        else:\n",
    "            results.append([token, 'IDnumber', startRow, endRow, startCol + 1, endCol + 1])\n",
    "            return\n",
    "#         print(previous_token)\n",
    "#     results.append([token, startRow, endRow, startCol + 1, endCol + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "rowCnt = 1\n",
    "token = ''\n",
    "idx = 0\n",
    "startCol = 0\n",
    "lastCol = 0\n",
    "results = []\n",
    "errors = []\n",
    "spaceTab = 0\n",
    "\n",
    "while idx < len(raw_text):\n",
    "    ch = raw_text[idx]\n",
    "#     print(repr(ch))\n",
    "    if ch == '\\n':\n",
    "        rowCnt += 1\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        token = ''\n",
    "        idx += 1\n",
    "        spaceTab = 0\n",
    "        startCol = idx\n",
    "        lastCol = idx\n",
    "        continue\n",
    "    \n",
    "    if ch == '\\t':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        token = ''\n",
    "        idx += 1\n",
    "        spaceTab += 3\n",
    "        startCol = idx\n",
    "        continue\n",
    "        \n",
    "    if ch == ' ':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        token = ''\n",
    "        idx += 1\n",
    "        startCol = idx\n",
    "        continue\n",
    "    \n",
    "    if ch == '(':\n",
    "        if raw_text[idx + 1] == '*':\n",
    "            isComment = 1\n",
    "            token = ''\n",
    "            idx += 1\n",
    "            startCol = idx\n",
    "            continue\n",
    "        else:\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "            token = ''\n",
    "            idx += 1\n",
    "            startCol = idx\n",
    "            continue\n",
    "        \n",
    "    if ch == ')':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "        token = ''\n",
    "        idx += 1\n",
    "        startCol = idx\n",
    "        continue\n",
    "    \n",
    "    if ch == ',':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        tokenParser(',', rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "        idx += 1\n",
    "        startCol = idx\n",
    "        token = ''\n",
    "        continue\n",
    "        \n",
    "    if ch == '.':\n",
    "        if raw_text[idx + 1] == '.':\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser('..', rowCnt, idx - lastCol + spaceTab, rowCnt, idx + 1 - lastCol + spaceTab)\n",
    "            idx += 2\n",
    "            token = ''\n",
    "            startCol = idx\n",
    "            continue\n",
    "            \n",
    "    if ch == ':':\n",
    "        if raw_text[idx + 1] == '=':\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser(':=', rowCnt, idx - lastCol + spaceTab, rowCnt, idx + 1 - lastCol + spaceTab)\n",
    "            idx += 2\n",
    "            token = ''\n",
    "            startCol = idx\n",
    "            continue\n",
    "        else:\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser(':', rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "            idx += 1\n",
    "            token = ''\n",
    "            startCol = idx\n",
    "            continue\n",
    "            \n",
    "    if ch == ';':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "        idx += 1\n",
    "        startCol = idx\n",
    "        token = ''\n",
    "        continue\n",
    "        \n",
    "    if ch == '+':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "        idx += 1\n",
    "        startCol = idx\n",
    "        token = ''\n",
    "        continue\n",
    "        \n",
    "    if ch == '-':\n",
    "        if re.match(r'^[0-9]$', raw_text[idx + 1]):\n",
    "            idx += 1\n",
    "            token = token + ch\n",
    "            continue\n",
    "        else:\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "            idx += 1\n",
    "            startCol = idx\n",
    "            token = ''\n",
    "            continue\n",
    "            \n",
    "    if ch == '*':\n",
    "        if raw_text[idx + 1] == ')' and isComment == 0:\n",
    "            errors.append([rowCnt, rowCnt, idx - lastCol + spaceTab, idx - lastCol + spaceTab, '[ERROR]: Is this the end of comment?'])\n",
    "            idx += 2\n",
    "            continue\n",
    "        elif raw_text[idx + 1] == ')':\n",
    "            isComment = 0\n",
    "            idx += 1\n",
    "            startCol = idx\n",
    "            token = ''\n",
    "            continue\n",
    "        else:\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "            idx += 1\n",
    "            startCol = idx\n",
    "            token = ''\n",
    "            continue\n",
    "    \n",
    "    token = token + ch\n",
    "    idx += 1\n",
    "\n",
    "if len(token) > 0:\n",
    "    tokenParser(token, rowCnt, startCol - lastCol, rowCnt, idx - 1 - lastCol)\n",
    "    \n",
    "print(rowCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing results:\n",
      "['x', 'IDnumber', 1, 1, 1, 1]\n",
      "['=', 'EQnumber', 1, 1, 3, 3]\n",
      "['y', 'IDnumber', 1, 1, 5, 5]\n",
      "['+', 'PLUSnumber', 1, 1, 7, 7]\n",
      "['56', 'ICONSTnumber', 1, 1, 9, 10]\n",
      "Errors list:\n"
     ]
    }
   ],
   "source": [
    "print('Parsing results:')\n",
    "for i in results:\n",
    "    print(i)\n",
    "\n",
    "print('Errors list:')\n",
    "for i in errors:\n",
    "    print(i)\n",
    "    \n",
    "fileOut = open('out.txt', 'w+')\n",
    "for i in results:\n",
    "    fileOut.write(str(i[0]) + ' ' + (i[1]) + ' ' + str(i[2]) + ' ' + str(i[3]) + ' ' + str(i[4]) + ' ' + str(i[5]) + '\\n')\n",
    "fileOut.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

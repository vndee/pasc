{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_file = './dictionary.json'\n",
    "parse_file = './Lexical/Test05.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = json.load(open(dict_file))\n",
    "raw_text = open(parse_file).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if n <= 1 then  \n",
      "\tfibResult := n  \n",
      "else  \n",
      "\tbegin  \n",
      "\t\ti := 2;  \n",
      "\t\twhile i >= n   \n",
      "\t\t\tloop  \n",
      "\t\t\t\ttmp := a + b;  \n",
      "\t\t\t\ti := i + 1;  \n",
      "\t\t\tendloop  \n",
      "\t\tfibResult := a  \n",
      "\tend  \n",
      "endif  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_text = raw_text.replace('\\n', ' \\n')\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "isComment = 0\n",
    "errors = []\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenParser(token, startRow, startCol, endRow, endCol):\n",
    "    if isComment == 1:\n",
    "        return\n",
    "\n",
    "    if token == '':\n",
    "        return\n",
    "    \n",
    "    if token in dic:\n",
    "        results.append([token, dic[token] + 'number', startRow, endRow, startCol + 1, endCol + 1])\n",
    "        return\n",
    "    else:        \n",
    "        if re.match(r'^[0-9]+$', token):\n",
    "            results.append([token, 'ICONSTnumber', startRow, endRow, startCol + 1, endCol + 1])\n",
    "            return\n",
    "        \n",
    "        if re.match(r'^\\'.\\'$', token):\n",
    "            results.append([token, 'CCONSTnumber', startRow, endRow, startCol + 1, endCol + 1])\n",
    "            return\n",
    "        \n",
    "        if re.match('^\\'.*\\'$', token):\n",
    "            results.append([token, 'SCONSTnumber', startRow, endRow, startCol + 1, endCol + 1])\n",
    "            return\n",
    "                \n",
    "        if re.match(r'^[0-9]+[a-zA-Z0-9]*$', token):\n",
    "            errors.append([startRow, endRow, startCol + 1, endCol + 1, token, '[SYNTAX ERROR]: Can not use this this as an identifier'])\n",
    "            return\n",
    "        else:\n",
    "            results.append([token, 'IDnumber', startRow, endRow, startCol + 1, endCol + 1])\n",
    "            return\n",
    "#         print(previous_token)\n",
    "#     results.append([token, startRow, endRow, startCol + 1, endCol + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "rowCnt = 1\n",
    "token = ''\n",
    "idx = 0\n",
    "startCol = 0\n",
    "lastCol = 0\n",
    "results = []\n",
    "errors = []\n",
    "spaceTab = 0\n",
    "\n",
    "while idx < len(raw_text):\n",
    "    ch = raw_text[idx]\n",
    "#     print(repr(ch))\n",
    "    if ch == '\\n':\n",
    "        rowCnt += 1\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        token = ''\n",
    "        idx += 1\n",
    "        spaceTab = 0\n",
    "        startCol = idx\n",
    "        lastCol = idx\n",
    "        continue\n",
    "    \n",
    "    if ch == '\\t':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        token = ''\n",
    "        idx += 1\n",
    "        spaceTab += 3\n",
    "        startCol = idx\n",
    "        continue\n",
    "        \n",
    "    if ch == ' ':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        token = ''\n",
    "        idx += 1\n",
    "        startCol = idx\n",
    "        continue\n",
    "    \n",
    "    if ch == '(':\n",
    "        if raw_text[idx + 1] == '*':\n",
    "            isComment = 1\n",
    "            token = ''\n",
    "            idx += 1\n",
    "            startCol = idx\n",
    "            continue\n",
    "        else:\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "            token = ''\n",
    "            idx += 1\n",
    "            startCol = idx\n",
    "            continue\n",
    "        \n",
    "    if ch == ')':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "        token = ''\n",
    "        idx += 1\n",
    "        startCol = idx\n",
    "        continue\n",
    "    \n",
    "    if ch == ',':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        tokenParser(',', rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "        idx += 1\n",
    "        startCol = idx\n",
    "        token = ''\n",
    "        continue\n",
    "        \n",
    "    if ch == '.':\n",
    "        if raw_text[idx + 1] == '.':\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser('..', rowCnt, idx - lastCol + spaceTab, rowCnt, idx + 1 - lastCol + spaceTab)\n",
    "            idx += 2\n",
    "            token = ''\n",
    "            startCol = idx\n",
    "            continue\n",
    "            \n",
    "    if ch == ':':\n",
    "        if raw_text[idx + 1] == '=':\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser(':=', rowCnt, idx - lastCol + spaceTab, rowCnt, idx + 1 - lastCol + spaceTab)\n",
    "            idx += 2\n",
    "            token = ''\n",
    "            startCol = idx\n",
    "            continue\n",
    "        else:\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser(':', rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "            idx += 1\n",
    "            token = ''\n",
    "            startCol = idx\n",
    "            continue\n",
    "            \n",
    "    if ch == ';':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "        idx += 1\n",
    "        startCol = idx\n",
    "        token = ''\n",
    "        continue\n",
    "        \n",
    "    if ch == '+':\n",
    "        tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "        tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "        idx += 1\n",
    "        startCol = idx\n",
    "        token = ''\n",
    "        continue\n",
    "        \n",
    "    if ch == '-':\n",
    "        if re.match(r'^[0-9]+$', raw_text[idx + 1]):\n",
    "            idx += 1\n",
    "            token = token + ch\n",
    "            continue\n",
    "        else:\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "            idx += 1\n",
    "            startCol = idx\n",
    "            token = ''\n",
    "            continue\n",
    "            \n",
    "    if ch == '*':\n",
    "        if raw_text[idx + 1] == ')' and isComment == 0:\n",
    "            errors.append([rowCnt, rowCnt, idx - lastCol + spaceTab, idx - lastCol + spaceTab, '[ERROR]: Is this the end of comment?'])\n",
    "            idx += 2\n",
    "            continue\n",
    "        elif raw_text[idx + 1] == ')':\n",
    "            isComment = 0\n",
    "            idx += 1\n",
    "            startCol = idx\n",
    "            token = ''\n",
    "            continue\n",
    "        else:\n",
    "            tokenParser(token, rowCnt, startCol - lastCol + spaceTab, rowCnt, idx - 1 - lastCol + spaceTab)\n",
    "            tokenParser(ch, rowCnt, idx - lastCol + spaceTab, rowCnt, idx - lastCol + spaceTab)\n",
    "            idx += 1\n",
    "            startCol = idx\n",
    "            token = ''\n",
    "            continue\n",
    "    \n",
    "    token = token + ch\n",
    "    idx += 1\n",
    "\n",
    "if len(token) > 0:\n",
    "    tokenParser(token, rowCnt, startCol - lastCol, rowCnt, idx - 1 - lastCol)\n",
    "    \n",
    "print(rowCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing results:\n",
      "['if', 'IFnumber', 1, 1, 1, 2]\n",
      "['n', 'IDnumber', 1, 1, 4, 4]\n",
      "['<=', 'LEnumber', 1, 1, 6, 7]\n",
      "['1', 'ICONSTnumber', 1, 1, 9, 9]\n",
      "['then', 'THENnumber', 1, 1, 11, 14]\n",
      "['fibResult', 'IDnumber', 2, 2, 5, 13]\n",
      "[':=', 'COLEQnumber', 2, 2, 15, 16]\n",
      "['n', 'IDnumber', 2, 2, 18, 18]\n",
      "['else', 'ELSEnumber', 3, 3, 1, 4]\n",
      "['begin', 'BEGINnumber', 4, 4, 5, 9]\n",
      "['i', 'IDnumber', 5, 5, 9, 9]\n",
      "[':=', 'COLEQnumber', 5, 5, 11, 12]\n",
      "['2', 'ICONSTnumber', 5, 5, 14, 14]\n",
      "[';', 'SEMInumber', 5, 5, 15, 15]\n",
      "['while', 'WHILEnumber', 6, 6, 9, 13]\n",
      "['i', 'IDnumber', 6, 6, 15, 15]\n",
      "['>=', 'GEnumber', 6, 6, 17, 18]\n",
      "['n', 'IDnumber', 6, 6, 20, 20]\n",
      "['loop', 'LOOPnumber', 7, 7, 13, 16]\n",
      "['tmp', 'IDnumber', 8, 8, 17, 19]\n",
      "[':=', 'COLEQnumber', 8, 8, 21, 22]\n",
      "['a', 'IDnumber', 8, 8, 24, 24]\n",
      "['+', 'PLUSnumber', 8, 8, 26, 26]\n",
      "['b', 'IDnumber', 8, 8, 28, 28]\n",
      "[';', 'SEMInumber', 8, 8, 29, 29]\n",
      "['i', 'IDnumber', 9, 9, 17, 17]\n",
      "[':=', 'COLEQnumber', 9, 9, 19, 20]\n",
      "['i', 'IDnumber', 9, 9, 22, 22]\n",
      "['+', 'PLUSnumber', 9, 9, 24, 24]\n",
      "['1', 'ICONSTnumber', 9, 9, 26, 26]\n",
      "[';', 'SEMInumber', 9, 9, 27, 27]\n",
      "['endloop', 'ENDLOOPnumber', 10, 10, 13, 19]\n",
      "['fibResult', 'IDnumber', 11, 11, 9, 17]\n",
      "[':=', 'COLEQnumber', 11, 11, 19, 20]\n",
      "['a', 'IDnumber', 11, 11, 22, 22]\n",
      "['end', 'ENDnumber', 12, 12, 5, 7]\n",
      "['endif', 'ENDIFnumber', 13, 13, 1, 5]\n",
      "Errors list:\n"
     ]
    }
   ],
   "source": [
    "print('Parsing results:')\n",
    "for i in results:\n",
    "    print(i)\n",
    "\n",
    "if isComment == 1:\n",
    "    errors.append([rowCnt, rowtCnt, idx, idx, '[ERROR] Comment are never terminated.'])\n",
    "print('Errors list:')\n",
    "for i in errors:\n",
    "    print(i)\n",
    "    \n",
    "fileOut = open('out.txt', 'w+')\n",
    "for i in results:\n",
    "    fileOut.write(str(i[0]) + ' ' + (i[1]) + ' ' + str(i[2]) + ' ' + str(i[3]) + ' ' + str(i[4]) + ' ' + str(i[5]) + '\\n')\n",
    "fileOut.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
